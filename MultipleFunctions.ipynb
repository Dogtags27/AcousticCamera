{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import acoular\n",
    "from pylab import figure, plot, axis, imshow, colorbar, show, savefig, clf\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import soundfile as sf\n",
    "import cv2\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wav_file='c:/Users/Hriday Desai/OneDrive/Desktop/Acoustic/recorder/recorder_output/records/audio.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'c:/Users/Hriday Desai/OneDrive/Desktop/Acoustic/recorder/recorder_output/frames'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of frames to be processed per second\n",
    "framesProcess = 44100//5  \n",
    "\n",
    "# Open the WAV file and read the audio data\n",
    "sample_rate, audio_data = wav.read(input_wav_file)\n",
    "sample_freq = sample_rate\n",
    "\n",
    "# Calculate the total number of frames based on the frame duration\n",
    "# num_frames = int(len(audio_data) // (sample_rate * frame_duration))\n",
    "num_frames = int(len(audio_data)//framesProcess)\n",
    "\n",
    "# os.makedirs(\"c:/Users/Hriday Desai/OneDrive/Desktop/Acoustic/recorder/recorder_output/split_audio\", exist_ok=True)\n",
    "audio_cuts=\"c:/Users/Hriday Desai/OneDrive/Desktop/Acoustic/recorder/recorder_output/audio_cuts\"\n",
    "os.makedirs(audio_cuts,exist_ok=True)\n",
    "\n",
    "\n",
    "# Iterate through each frame and save it as a separate HDF5 file\n",
    "for i in range(num_frames):\n",
    "    # Extract the audio data for the current frame\n",
    "    frame_start = int(i * framesProcess)\n",
    "    frame_end = int((i + 1) * framesProcess)\n",
    "    frame_audio_data = audio_data[frame_start:frame_end]\n",
    "\n",
    "    output_audio_cut_file=f\"c:/Users/Hriday Desai/OneDrive/Desktop/Acoustic/recorder/recorder_output/audio_cuts/audio_cut_{i+1}.wav\"\n",
    "    wav.write(output_audio_cut_file, sample_rate, frame_audio_data)\n",
    "    \n",
    "    # Create the output HDF5 file path for the current frame\n",
    "    output_h5_file = f\"{output_dir}/frame_{i + 1}.h5\"\n",
    "\n",
    "    # Create an HDF5 file for the current frame\n",
    "    with h5py.File(output_h5_file, 'w') as hf:\n",
    "        # Create a dataset to store audio data\n",
    "        hf.create_dataset('/time_data', data=frame_audio_data, dtype=np.int16)\n",
    "\n",
    "        # Add attribute for sample rate\n",
    "        hf['/time_data'].attrs['sample_freq'] = sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micgeofile = 'C:/Users/Hriday Desai/OneDrive/Desktop/Acoustic/recorder/xml/microphone.xml'\n",
    "\n",
    "mg = acoular.MicGeom( from_file=micgeofile )\n",
    "\n",
    "# Check the number of microphones\n",
    "num_mics = mg.num_mics\n",
    "print(\"Number of microphones:\", num_mics)\n",
    "# Define the rectilinear grid\n",
    "rg = acoular.RectGrid(x_min=-2, x_max=2, y_min=-2, y_max=2, z=2, increment=0.02)\n",
    "# Define the steering vector\n",
    "st = acoular.SteeringVector(grid=rg, mics=mg)\n",
    "# Compute the beamformer base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"C:/Users/Hriday Desai/OneDrive/Desktop/Acoustic/recorder/recorder_output/frame_images\", exist_ok=True)\n",
    "audio_files_count=0\n",
    "for i in range(num_frames):\n",
    "    output_h5_file = f\"{output_dir}/frame_{i + 1}.h5\"\n",
    "    datafile = output_h5_file\n",
    "    \n",
    "    audio_cut_file=f\"{audio_cuts}/audio_cut_{i+1}.wav\"\n",
    "    y, sr = librosa.load(audio_cut_file, sr=None)\n",
    "\n",
    "    # Compute the FFT (Fast Fourier Transform) to obtain the power spectrum\n",
    "    fft_result = np.fft.fft(y)\n",
    "\n",
    "    # Compute the frequencies corresponding to the FFT bins\n",
    "    fft_freqs = np.fft.fftfreq(len(y), 1/sr)\n",
    "\n",
    "    # Discard negative frequencies\n",
    "    positive_fft_freqs = fft_freqs[:len(fft_freqs)//2]\n",
    "    positive_fft_result = fft_result[:len(fft_result)//2]\n",
    "\n",
    "    # Find the frequency with the maximum power\n",
    "    max_power_index = np.argmax(np.abs(positive_fft_result))\n",
    "    max_power_frequency = positive_fft_freqs[max_power_index]\n",
    "\n",
    "    # print(\"Max Power Frequency:\", max_power_frequency, \"Hz\")\n",
    "    \n",
    "    ts = acoular.TimeSamples(name=datafile)\n",
    "    ps = acoular.PowerSpectra(time_data=ts, block_size=1024, window='Hanning')\n",
    "    bb = acoular.BeamformerFunctional(freq_data=ps, steer=st)\n",
    "    # Compute the synthetic sound field\n",
    "    pm = bb.synthetic(max_power_frequency, 3)\n",
    "    # Compute the sound pressure level\n",
    "    Lm = acoular.L_p(pm)\n",
    "    \n",
    "    imshow( Lm.T, origin='lower', vmin=Lm.max()-0.5, extent=rg.extend() ,interpolation=\"bicubic\", cmap=\"rainbow\")\n",
    "\n",
    "    axis('off')\n",
    "    \n",
    "    output_file = f\"C:/Users/Hriday Desai/OneDrive/Desktop/Acoustic/recorder/recorder_output/frame_images/frame_{i+1}.png\"\n",
    "    audio_files_count+=1\n",
    "    # Save the plot as an image file\n",
    "    savefig(output_file, bbox_inches='tight', pad_inches=0)\n",
    "    clf()\n",
    "    # Clear the current plot to prepare for the next frame\n",
    "    # clf()  # Clear the current figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract frames from video\n",
    "video_path=\"C:/Users/Hriday Desai/OneDrive/Desktop/Acoustic/recorder/recorder_output/records/video.avi\"\n",
    "output_folder=\"C:/Users/Hriday Desai/OneDrive/Desktop/Acoustic/recorder/recorder_output/imageshots\"\n",
    "frame_rate_ms=400\n",
    "\n",
    "def extract_frames(video_path, output_folder, frame_rate_ms):\n",
    "    # Create output folder if not exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Open video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video file.\")\n",
    "        return\n",
    "\n",
    "    # Get frame rate of the video\n",
    "    frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Calculate frame interval based on desired frame rate (in milliseconds)\n",
    "    # frame_interval = int(frame_rate * frame_rate_ms)\n",
    "    \n",
    "    frame_interval = frame_rate_ms\n",
    "    \n",
    "    # Variables to track frame number and current time\n",
    "    frame_count = 0\n",
    "    current_time = 0\n",
    "\n",
    "    # Loop through video frames\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Check if it's time to save the frame\n",
    "        if current_time >= frame_interval:\n",
    "            # Save frame as image\n",
    "            image_path = os.path.join(output_folder, f\"frame_{1+frame_count}.png\")\n",
    "            cv2.imwrite(image_path, frame)\n",
    "            frame_count += 1\n",
    "            current_time = 0\n",
    "\n",
    "        # Update current time\n",
    "        current_time += int(1000 / frame_rate)\n",
    "\n",
    "        # Move to next frame\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, cap.get(cv2.CAP_PROP_POS_FRAMES) + 1)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    print(f\"Frames extracted: {frame_count}\")\n",
    "    print(\"Extraction complete.\")\n",
    "    return frame_count\n",
    "frame_count=extract_frames(video_path, output_folder, frame_rate_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_frame_count=min(frame_count,audio_files_count)\n",
    "audio_images_directory=\"C:/Users/Hriday Desai/OneDrive/Desktop/Acoustic/recorder/recorder_output/frame_images\"\n",
    "video_images_directory=\"C:/Users/Hriday Desai/OneDrive/Desktop/Acoustic/recorder/recorder_output/imageshots\"\n",
    "\n",
    "output_folder=\"C:/Users/Hriday Desai/OneDrive/Desktop/Acoustic/recorder/recorder_output/merged_images\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_images(background_img, overlay_img, output_path):\n",
    "    # Read the images\n",
    "    background = cv2.imread(str(background_img))\n",
    "    overlay = cv2.imread(str(overlay_img))\n",
    "\n",
    "    # Resize overlay image to match background dimensions\n",
    "    overlay = cv2.resize(overlay, (background.shape[1], background.shape[0]))\n",
    "    # Horizontally flip the overlay image\n",
    "    overlay_flipped = cv2.flip(overlay, 1)\n",
    "    # Blend the images using simple addition\n",
    "    blended = cv2.addWeighted(background, 0.3, overlay_flipped, 0.7, 0)\n",
    "\n",
    "    # Write the blended image to the output path\n",
    "    cv2.imwrite(str(output_path), blended)\n",
    "\n",
    "    print(f\"Merged image saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directories containing the images\n",
    "imageshots_dir = video_images_directory\n",
    "frame_images_dir = audio_images_directory\n",
    "\n",
    "imageshots_files=[]\n",
    "frame_images_files=[]\n",
    "merged_images_files=[]\n",
    "for i in range(1,merge_frame_count+1):\n",
    "    imageshots_files.append(f\"C:/Users/Hriday Desai/OneDrive/Desktop/Acoustic/recorder/recorder_output/imageshots/frame_{i}.png\")\n",
    "    frame_images_files.append(f\"C:/Users/Hriday Desai/OneDrive/Desktop/Acoustic/recorder/recorder_output/frame_images/frame_{i}.png\")\n",
    "    merged_images_files.append(f\"C:/Users/Hriday Desai/OneDrive/Desktop/Acoustic/recorder/recorder_output/merged_images/frame_{i}.png\")\n",
    "\n",
    "output_dir=output_folder\n",
    "# Iterate through the PNG files and merge them\n",
    "# for imageshot_file in imageshots_files:\n",
    "for j in range(1,merge_frame_count+1):\n",
    "    frame_image_path = frame_images_files[j-1]\n",
    "    imageshot_path = imageshots_files[j-1]\n",
    "    merged_image_path = merged_images_files[j-1]\n",
    "    \n",
    "    merge_images(imageshot_path,frame_image_path,merged_image_path)\n",
    "\n",
    "print(\"Merge process complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import ImageSequenceClip\n",
    "from pathlib import Path\n",
    "# Specify the directory containing the merged images\n",
    "merged_images_dir = Path(\"C:/Users/Hriday Desai/OneDrive/Desktop/Acoustic/recorder/recorder_output/merged_images\")\n",
    "\n",
    "# Get a list of image files in the directory\n",
    "image_files = sorted([str(f) for f in merged_images_dir.iterdir() if f.suffix == '.png'])\n",
    "\n",
    "# Specify the frame rate (5 images per second)\n",
    "fps = 5\n",
    "\n",
    "# Create an ImageSequenceClip from the image files\n",
    "clip = ImageSequenceClip(image_files, fps=fps)\n",
    "\n",
    "# Specify the output video file path\n",
    "output_video_path = \"C:/Users/Hriday Desai/OneDrive/Desktop/Acoustic/recorder/recorder_output/records/output_video.mp4\"\n",
    "\n",
    "# Write the clip to the output video file\n",
    "clip.write_videofile(output_video_path, codec='libx264')\n",
    "\n",
    "print(f\"Video saved: {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "# Load the audio file\n",
    "audio_file = \"C:/Users/Hriday Desai/OneDrive/Desktop/Acoustic/recorder/recorder_output/records/audio.wav\"\n",
    "y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "\n",
    "# Compute the FFT (Fast Fourier Transform) to obtain the power spectrum\n",
    "fft_result = np.fft.fft(y)\n",
    "\n",
    "# Compute the frequencies corresponding to the FFT bins\n",
    "fft_freqs = np.fft.fftfreq(len(y), 1/sr)\n",
    "\n",
    "# Discard negative frequencies\n",
    "positive_fft_freqs = fft_freqs[:len(fft_freqs)//2]\n",
    "positive_fft_result = fft_result[:len(fft_result)//2]\n",
    "\n",
    "# Find the frequency with the maximum power\n",
    "max_power_index = np.argmax(np.abs(positive_fft_result))\n",
    "max_power_frequency = positive_fft_freqs[max_power_index]\n",
    "\n",
    "print(\"Max Power Frequency:\", max_power_frequency, \"Hz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
